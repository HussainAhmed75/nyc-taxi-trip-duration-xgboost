# -*- coding: utf-8 -*-
"""Final project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hn-4EbnN8Y_UhVb8JmUtRxVOrrBX22bU
"""
import kagglehub
# Download latest version
path = kagglehub.dataset_download("yasserh/nyc-taxi-trip-duration")

print("Path to dataset files:", path)

import os

os.listdir(path)

import pandas as pd

df = pd.read_csv(f"{path}/NYC.csv", engine="python")

df

df.info()

df.isnull().sum().sort_values(ascending=True)

df.duplicated().sum()

df.drop(columns=['id'], inplace=True)

from sklearn.preprocessing import LabelEncoder
lb = LabelEncoder()
df['store_and_fwd_flag'] = lb.fit_transform(df['store_and_fwd_flag'])

df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])
df['pickup_hour'] = df['pickup_datetime'].dt.hour
df['pickup_day']  = df['pickup_datetime'].dt.day
df['pickup_month'] = df['pickup_datetime'].dt.month
df['pickup_weekday'] = df['pickup_datetime'].dt.weekday
df['pickup_is_weekend'] = df['pickup_weekday'].isin([4]).astype(int)

df.drop(columns=['pickup_datetime'], inplace=True)

import numpy as np
def haversine_distance(lon1, lat1, lon2, lat2):
    """
    Calculate the great circle distance between two points
    on the earth (specified in decimal degrees)
    """
    # 1. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù…Ù† Ø¯Ø±Ø¬Ø§Øª Ø¥Ù„Ù‰ Ø±Ø§Ø¯ÙŠØ§Ù† (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹)
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])
    # 2. ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹Ø§Ø¯Ù„Ø© Haversine
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    # 3. Ù†ØµÙ Ù‚Ø·Ø± Ø§Ù„Ø£Ø±Ø¶ Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ± (6371) Ø£Ùˆ Ø¨Ø§Ù„Ù…ÙŠÙ„ (3956)
    r = 6371
    return c * r
# Ø§ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ù€ DataFrame Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø§Ø³Ù…Ù‡ df
# Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù…Ø³Ø§ÙØ©:
df['distance_km'] = haversine_distance(
    df['pickup_longitude'],
    df['pickup_latitude'],
    df['dropoff_longitude'],
    df['dropoff_latitude']
)

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
print(df.head())

df.drop(['pickup_longitude', 'pickup_latitude',
         'dropoff_longitude', 'dropoff_latitude'], axis=1, inplace=True)

df

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np # Import numpy for np.log1p

plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
sns.histplot(df["trip_duration"], bins=100)
plt.title("Raw Trip Duration")

# Ensure 'trip_duration_log' exists before plotting
# This line was missing when the error occurred previously.
df["trip_duration_log"] = np.log1p(df["trip_duration"])

plt.subplot(1,2,2)
sns.histplot(df["trip_duration_log"], bins=100)
plt.title("Log Transformed Trip Duration")

plt.show()

import folium


map_center = [40.758896, -73.985130]
map_nyc = folium.Map(location=map_center, zoom_start=12)

df_for_map = pd.read_csv(f"{path}/NYC.csv")

for _, row in df_for_map.head(1000).iterrows():
    folium.Marker([row['pickup_latitude'], row['pickup_longitude']]).add_to(map_nyc)

map_nyc

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6))
sns.histplot(df["trip_duration"], bins=100, kde=True)
plt.title("Trip Duration Distribution (Raw)")
plt.xlabel("Trip Duration (seconds)")
plt.ylabel("Count")
plt.grid(True)
plt.show()

Q1 = df["trip_duration"].quantile(0.25)
Q3 = df["trip_duration"].quantile(0.75)
IQR = Q3 - Q1

lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR

df = df[
    (df["trip_duration"] >= lower) &
    (df["trip_duration"] <= upper)
]

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6))
sns.histplot(df["trip_duration"], bins=100, kde=True)
plt.title("Trip Duration Distribution (Raw)")
plt.xlabel("Trip Duration (seconds)")
plt.ylabel("Count")
plt.grid(True)
plt.show()

plt.figure(figsize=(10,4))
sns.boxplot(x=df["trip_duration"])
plt.title("Trip Duration Boxplot (Outliers)")
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
sns.histplot(df["distance_km"], kde=True)
plt.title("distance_km (Raw)")
plt.xlabel("Trip Duration (seconds)")
plt.ylabel("Count")
plt.grid(True)
plt.show()

Q1 = df["distance_km"].quantile(0.25)
Q3 = df["distance_km"].quantile(0.75)
IQR = Q3 - Q1

lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR

df = df[
    (df["distance_km"] >= lower) &
    (df["distance_km"] <= upper)
]

plt.figure(figsize=(10,6))
sns.histplot(df["distance_km"], bins=100, kde=True)
plt.title("distance_km (Raw)")
plt.xlabel("Trip Duration (seconds)")
plt.ylabel("Count")
plt.grid(True)
plt.show()

df["distance_km"].describe()



df["speed_kmh"] = df["distance_km"] / (df["trip_duration"] / 3600)

plt.figure(figsize=(10,6))
sns.histplot(df["speed_kmh"], bins=100, kde=True)
plt.title("speed_kmh (Raw)")
plt.xlabel("Trip Duration (seconds)")
plt.ylabel("Count")
plt.grid(True)
plt.show()

df = df[
    (df["speed_kmh"] >= 1) &
    (df["speed_kmh"] <= 80)
]

plt.figure(figsize=(10,6))
sns.histplot(df["speed_kmh"], bins=80, kde=True)
plt.xlim(0, 80)
plt.title("speed_kmh (Cleaned)")
plt.xlabel("Speed (km/h)")
plt.ylabel("Count")
plt.grid(True)
plt.show()

df["trip_duration_log"] = np.log1p(df["trip_duration"])
df.drop(columns=["trip_duration"], inplace=True)

df.drop(columns=['dropoff_datetime'], inplace=True)

annot = True

linewidths = 1
linecolor = "yellow"

plt.figure(figsize=(10, 10))
ax = sns.heatmap(df.corr(), annot=annot, fmt="0.1g", cmap="YlGnBu",linewidths=linewidths,
                linecolor=linecolor)
ax.set_xticklabels(df.columns)
ax.set_yticklabels(df.columns)
ax.set_xlabel("Custom X Label")
ax.set_ylabel("Custom Y Label")
plt.show()

df_weekday = (
    df
    .groupby("pickup_weekday")["trip_duration_log"]
    .mean()
)
df_weekday_seconds = np.expm1(df_weekday)
df_weekday_seconds.plot(
    kind="line",
    marker="o",
    linewidth=2
)
plt.title("Average Trip Duration by Weekday")
plt.xlabel("Weekday (0=Mon)")
plt.ylabel("Average Trip Duration (seconds)")
plt.show()

df.describe()

df.isna().sum()

from sklearn.model_selection import train_test_split
features = ['passenger_count', 'pickup_hour', 'pickup_day',
            'pickup_weekday', 'pickup_is_weekend', 'distance_km']
X = df[features]
y = df['trip_duration_log']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import MinMaxScaler
my_scaler = MinMaxScaler(feature_range=(0,1))
X_train = my_scaler.fit_transform(X_train)
X_test = my_scaler.transform(X_test)


from sklearn.linear_model import LinearRegression , Lasso ,Ridge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.ensemble import BaggingRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.experimental import enable_hist_gradient_boosting
from sklearn.ensemble import HistGradientBoostingRegressor
import xgboost as xgb
from xgboost import XGBRegressor
from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_squared_error
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
import lightgbm as lgb
from lightgbm import LGBMRegressor

models = {
     "XGBoost": XGBRegressor(xgb_model = XGBRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=10,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    objective="reg:squarederror",
    verbosity=0
)
),
}
errors=[]
for model_name , model in models.items():
    model.fit(X_train,y_train)
    MAE_Train = mean_absolute_error(y_train,model.predict(X_train))
    MAE_Test  =  mean_absolute_error(y_test,model.predict(X_test))
    MSE_Train = mean_squared_error(y_train,model.predict(X_train))
    MSE_Test  =  mean_squared_error(y_test,model.predict(X_test))
    RMSE_Train = root_mean_squared_error(y_train,model.predict(X_train))
    RMSE_Test  =  root_mean_squared_error(y_test,model.predict(X_test))
    R_Train = r2_score(y_train,model.predict(X_train))
    R_Test  =  r2_score(y_test,model.predict(X_test))
    errors.append([MAE_Train,MSE_Train,RMSE_Train,R_Train,MAE_Test,MSE_Test,RMSE_Test,R_Test])

pd.DataFrame(errors,columns=["MAE_Train","MSE_Train","RMSE_Train","R_Train","MAE_Test","MSE_Test","RMSE_Test","R_Test"],index=models.keys())

df



import gradio as gr
import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle

APP_TITLE = "ðŸš• NYC Taxi Trip Duration Predictor"

# =========================
# Train Model on YOUR FULL DATA
# =========================
def train_xgboost_model(df):
    """
    ØªØ¯Ø±ÙŠØ¨ XGBoost Ø¹Ù„Ù‰ Ø§Ù„Ù€ DataFrame Ø¨ØªØ§Ø¹Ùƒ ÙƒÙ„Ù‡ (1.25 Ù…Ù„ÙŠÙˆÙ† row)

    Required columns in df:
    - passenger_count
    - pickup_hour
    - pickup_weekday
    - pickup_is_weekend
    - pickup_month
    - distance_km
    - trip_duration (OR log_trip_duration)
    """

    print("="*70)
    print("ðŸš€ Starting XGBoost Training on YOUR FULL DATASET")
    print("="*70)

    # Check required columns
    feature_cols = ['passenger_count', 'pickup_hour', 'pickup_weekday',
                    'pickup_is_weekend', 'pickup_month', 'distance_km']

    missing_features = [col for col in feature_cols if col not in df.columns]
    if missing_features:
        raise ValueError(f"âŒ Missing feature columns: {missing_features}")

    # Check target column (support multiple names)
    target_col = None
    possible_targets = ['log_trip_duration', 'trip_duration_log', 'trip_duration']

    for col in possible_targets:
        if col in df.columns:
            target_col = col
            print(f"âœ… Found target column: '{col}'")
            break

    if target_col is None:
        print(f"\nâŒ ERROR: Missing target column!")
        print(f"   Available columns: {list(df.columns)}")
        print(f"\nðŸ’¡ Please check your column name for trip duration.")
        raise ValueError(
            "âŒ Missing target column!\n"
            f"   Your columns: {list(df.columns)}"
        )

    # If trip_duration (not logged), create log version
    if target_col == 'trip_duration':
        print("âš™ï¸ Creating log transform from 'trip_duration'...")
        df = df.copy()
        df['log_trip_duration'] = np.log1p(df['trip_duration'])
        target_col = 'log_trip_duration'
        print("âœ… log_trip_duration created!")

    # Rename if needed
    if target_col == 'trip_duration_log':
        print("âš™ï¸ Using 'trip_duration_log' as target")
        df = df.copy()
        df['log_trip_duration'] = df['trip_duration_log']
        target_col = 'log_trip_duration'

    print(f"\nðŸ“Š Dataset Info:")
    print(f"   Total Rows: {len(df):,}")
    print(f"   Total Columns: {len(df.columns)}")
    print(f"   Available Columns: {list(df.columns)}")
    print(f"   Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

    # Features and Target
    features = ['passenger_count', 'pickup_hour', 'pickup_weekday',
                'pickup_is_weekend', 'pickup_month', 'distance_km']

    X = df[features].copy()
    y = df['log_trip_duration'].copy()

    print(f"\nðŸ“ Features: {features}")
    print(f"   X shape: {X.shape}")
    print(f"   y shape: {y.shape}")

    # Train/Test Split
    print(f"\nðŸ”€ Splitting data (80% train, 20% test)...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    print(f"   Train: {len(X_train):,} samples")
    print(f"   Test:  {len(X_test):,} samples")

    # XGBoost Model (same as your parameters)
    print(f"\nðŸ¤– Training XGBoost Model...")
    print(f"   Parameters:")
    print(f"   - n_estimators: 500")
    print(f"   - learning_rate: 0.05")
    print(f"   - max_depth: 10")
    print(f"   - subsample: 0.8")
    print(f"   - colsample_bytree: 0.8")

    model = XGBRegressor(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=10,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        objective='reg:squarederror',
        verbosity=1,
        n_jobs=-1
    )

    model.fit(X_train, y_train)

    print(f"\nâœ… Model Training Completed!")

    # Calculate ALL Metrics
    print(f"\nðŸ“Š Calculating Performance Metrics...")
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    MAE_Train = mean_absolute_error(y_train, y_train_pred)
    MAE_Test = mean_absolute_error(y_test, y_test_pred)

    MSE_Train = mean_squared_error(y_train, y_train_pred)
    MSE_Test = mean_squared_error(y_test, y_test_pred)

    RMSE_Train = np.sqrt(MSE_Train)
    RMSE_Test = np.sqrt(MSE_Test)

    R_Train = r2_score(y_train, y_train_pred)
    R_Test = r2_score(y_test, y_test_pred)

    # Store metrics
    metrics = {
        'MAE_Train': MAE_Train,
        'MSE_Train': MSE_Train,
        'RMSE_Train': RMSE_Train,
        'R_Train': R_Train,
        'MAE_Test': MAE_Test,
        'MSE_Test': MSE_Test,
        'RMSE_Test': RMSE_Test,
        'R_Test': R_Test
    }

    model.metrics = metrics

    # Print Results
    print(f"\n{'='*70}")
    print(f"ðŸ“ˆ MODEL PERFORMANCE METRICS")
    print(f"{'='*70}")
    print(f"{'Metric':<15} {'Train':<25} {'Test':<25}")
    print(f"{'-'*70}")
    print(f"{'MAE':<15} {MAE_Train:<25.6f} {MAE_Test:<25.6f}")
    print(f"{'MSE':<15} {MSE_Train:<25.6f} {MSE_Test:<25.6f}")
    print(f"{'RMSE':<15} {RMSE_Train:<25.6f} {RMSE_Test:<25.6f}")
    print(f"{'RÂ²':<15} {R_Train:<25.6f} {R_Test:<25.6f}")
    print(f"{'='*70}\n")

    return model


# =========================
# Initialize Model with YOUR df
# =========================
print("\nðŸ” Looking for your DataFrame 'df'...")

if 'df' not in globals():
    raise NameError(
        "âŒ DataFrame 'df' not found!\n"
        "Please load your data first:\n"
        "   df = pd.read_csv('your_data.csv')\n"
        "Then run this code."
    )

print(f"âœ… Found df with shape: {df.shape}")

# Train the model on YOUR FULL DATA
model = train_xgboost_model(df)

# Save model
try:
    with open('xgb_taxi_real.pkl', 'wb') as f:
        pickle.dump(model, f)
    print("ðŸ’¾ Model saved to: xgb_taxi_real.pkl\n")
except Exception as e:
    print(f"âš ï¸ Could not save model: {e}\n")


# =========================
# Prediction Function
# =========================
def predict_trip_duration(
    passenger_count,
    pickup_hour,
    pickup_weekday,
    pickup_is_weekend,
    pickup_month,
    distance_km
):
    try:
        df_input = pd.DataFrame([{
            "passenger_count": int(passenger_count),
            "pickup_hour": int(pickup_hour),
            "pickup_weekday": int(pickup_weekday),
            "pickup_is_weekend": int(pickup_is_weekend),
            "pickup_month": int(pickup_month),
            "distance_km": float(distance_km),
        }])

        pred_log = model.predict(df_input)
        pred_seconds = float(np.expm1(pred_log)[0])
        pred_minutes = pred_seconds / 60

        result_text = (
            f"## ðŸš• Predicted Trip Duration\n\n"
            f"### â±ï¸ {pred_minutes:.1f} minutes\n"
            f"**({pred_seconds:.0f} seconds)**\n\n"
        )

        if pred_minutes < 5:
            result_text += "âš¡ **Very short trip**"
        elif pred_minutes < 15:
            result_text += "ðŸš— **Short trip**"
        elif pred_minutes < 30:
            result_text += "ðŸš™ **Medium trip**"
        else:
            result_text += "ðŸšŒ **Long trip**"

        return result_text, df_input

    except Exception as e:
        return f"âŒ Prediction failed: {str(e)}", pd.DataFrame()


# =========================
# Gradio Interface
# =========================
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown(f"# {APP_TITLE}")
    gr.Markdown(f"**Trained on {len(df):,} real NYC taxi trips using XGBoost**")

    with gr.Row():
        with gr.Column():
            passenger_count = gr.Number(
                label="ðŸ‘¥ Passenger Count",
                value=1,
                minimum=1,
                maximum=6
            )
            pickup_hour = gr.Slider(
                0, 23,
                step=1,
                label="ðŸ• Pickup Hour (0-23)",
                value=14
            )
            pickup_weekday = gr.Slider(
                0, 6,
                step=1,
                label="ðŸ“… Weekday (0=Mon, 6=Sun)",
                value=2
            )

        with gr.Column():
            pickup_is_weekend = gr.Radio(
                choices=[("Weekday", 0), ("Weekend", 1)],
                label="ðŸŽ‰ Weekend?",
                value=0
            )
            pickup_month = gr.Slider(
                1, 12,
                step=1,
                label="ðŸ“† Month (1-12)",
                value=6
            )
            distance_km = gr.Number(
                label="ðŸ“ Distance (km)",
                value=5.0,
                minimum=0.1
            )

    predict_btn = gr.Button("ðŸ”® Predict Trip Duration", variant="primary", size="lg")

    output_text = gr.Markdown()

    with gr.Accordion("ðŸ“Š Input Features", open=False):
        output_df = gr.Dataframe(label="Features Used")

    with gr.Accordion("ðŸ“ˆ Model Performance Metrics", open=True):
        if hasattr(model, 'metrics'):
            metrics_df = pd.DataFrame([model.metrics])
            metrics_df = metrics_df.round(6)
            gr.Dataframe(
                value=metrics_df,
                label="Training & Testing Metrics (MAE | MSE | RMSE | RÂ²)"
            )

    gr.Examples(
        examples=[
            [1, 8, 1, 0, 3, 3.5],    # Morning rush
            [2, 18, 4, 0, 6, 8.2],   # Evening rush
            [4, 23, 5, 1, 12, 2.1],  # Late night weekend
            [1, 14, 2, 0, 9, 15.5],  # Long afternoon trip
        ],
        inputs=[passenger_count, pickup_hour, pickup_weekday,
                pickup_is_weekend, pickup_month, distance_km],
        label="ðŸ’¡ Try These Examples"
    )

    predict_btn.click(
        fn=predict_trip_duration,
        inputs=[passenger_count, pickup_hour, pickup_weekday,
                pickup_is_weekend, pickup_month, distance_km],
        outputs=[output_text, output_df]
    )

if __name__ == "__main__":
    demo.launch()